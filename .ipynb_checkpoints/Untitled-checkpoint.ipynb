{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 贝叶斯模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 知识点梳理\n",
    "1、相关概念（生成模型、判别模型)\n",
    "2、先验概率、条件概率\n",
    "3、贝叶斯决策理论\n",
    "4、贝叶斯定理公式\n",
    "5、极值问题情况下的每个类的分类概率\n",
    "6、下溢问题如何解决\n",
    "7、零概率问题如何解决？\n",
    "8、优缺点\n",
    "9、sklearn参数详解，Python绘制决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn接口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2)\n",
    "clf = GaussianNB().fit(X_train, y_train)\n",
    "print (\"Classifier Score:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编号\t色泽\t根蒂\t敲声\t纹理\t脐部\t触感\t好瓜\n",
    "1\t青绿\t蜷缩\t浊响\t清晰\t凹陷\t硬滑\t是\n",
    "2\t乌黑\t蜷缩\t沉闷\t清晰\t凹陷\t硬滑\t是\n",
    "3\t乌黑\t蜷缩\t浊响\t清晰\t凹陷\t硬滑\t是\n",
    "4\t青绿\t蜷缩\t沉闷\t清晰\t凹陷\t硬滑\t是\n",
    "5\t浅白\t蜷缩\t浊响\t清晰\t凹陷\t硬滑\t是\n",
    "6\t青绿\t稍蜷\t浊响\t清晰\t稍凹\t软粘\t是\n",
    "7\t乌黑\t稍蜷\t浊响\t稍糊\t稍凹\t软粘\t是\n",
    "8\t乌黑\t稍蜷\t浊响\t清晰\t稍凹\t硬滑\t是\n",
    "9\t乌黑\t稍蜷\t沉闷\t稍糊\t稍凹\t硬滑\t否\n",
    "10\t青绿\t硬挺\t清脆\t清晰\t平坦\t软粘\t否\n",
    "11\t浅白\t硬挺\t清脆\t模糊\t平坦\t硬滑\t否\n",
    "12\t浅白\t蜷缩\t浊响\t模糊\t平坦\t软粘\t否\n",
    "13\t青绿\t稍蜷\t浊响\t稍糊\t凹陷\t硬滑\t否\n",
    "14\t浅白\t稍蜷\t沉闷\t稍糊\t凹陷\t硬滑\t否\n",
    "15\t乌黑\t稍蜷\t浊响\t清晰\t稍凹\t软粘\t否\n",
    "16\t浅白\t蜷缩\t浊响\t模糊\t平坦\t硬滑\t否\n",
    "17\t青绿\t蜷缩\t沉闷\t稍糊\t稍凹\t硬滑\t否"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 相关概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成模型：在概率统计理论中, 生成模型是指能够随机生成观测数据的模型，尤其是在给定某些隐含参数的条件下。它给观测值和标注数据序列指定一个联合概率分布。在机器学习中，生成模型可以用来直接对数据建模（例如根据某个变量的概率密度函数进行数据采样），也可以用来建立变量间的条件概率分布。条件概率分布可以由生成模型根据贝叶斯定理形成。常见的基于生成模型算法有高斯混合模型和其他混合模型、隐马尔可夫模型、随机上下文无关文法、朴素贝叶斯分类器、AODE分类器、潜在狄利克雷分配模型、受限玻尔兹曼机  \n",
    "<br>\n",
    "举例：要确定一个瓜是好瓜还是坏瓜，用判别模型的方法是从历史数据中学习到模型，然后通过提取这个瓜的特征来预测出这只瓜是好瓜的概率，是坏瓜的概率。\n",
    "\n",
    "<br>\n",
    "判别模型: 在机器学习领域判别模型是一种对未知数据 y 与已知数据 x 之间关系进行建模的方法。判别模型是一种基于概率理论的方法。已知输入变量 x ，判别模型通过构建条件概率分布 P(y|x) 预测 y 。常见的基于判别模型算法有逻辑回归、线性回归、支持向量机、提升方法、条件随机场、人工神经网络、随机森林、感知器\n",
    "\n",
    "举例：利用生成模型是根据好瓜的特征首先学习出一个好瓜的模型，然后根据坏瓜的特征学习得到一个坏瓜的模型，然后从需要预测的瓜中提取特征，放到生成好的好瓜的模型中看概率是多少，在放到生产的坏瓜模型中看概率是多少，哪个概率大就预测其为哪个。\n",
    "\n",
    "<br>\n",
    "生成模型是所有变量的全概率模型，而判别模型是在给定观测变量值前提下目标变量条件概率模型。因此生成模型能够用于模拟（即生成）模型中任意变量的分布情况，而判别模型只能根据观测变量得到目标变量的采样。判别模型不对观测变量的分布建模，因此它不能够表达观测变量与目标变量之间更复杂的关系。因此，生成模型更适用于无监督的任务，如分类和聚类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 先验概率、条件概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "条件概率: 就是事件A在事件B发生的条件下发生的概率。条件概率表示为P（A|B），读作“A在B发生的条件下发生的概率”。\n",
    "\n",
    "\n",
    "先验概率: 在贝叶斯统计中，某一不确定量 p 的先验概率分布是在考虑\"观测数据\"前，能表达 p 不确定性的概率分布。它旨在描述这个不确定量的不确定程度，而不是这个不确定量的随机性。这个不确定量可以是一个参数，或者是一个隐含变量。\n",
    "后验概率: 在贝叶斯统计中，一个随机事件或者一个不确定事件的后验概率是在考虑和给出相关证据或数据后所得到的条件概率。同样，后验概率分布是一个未知量（视为随机变量）基于试验和调查后得到的概率分布。“后验”在本文中代表考虑了被测试事件的相关证据。\n",
    "通过上述西瓜的数据集来看\n",
    "\n",
    "条件概率，就是在条件为瓜的颜色是青绿的情况下，瓜是好瓜的概率\n",
    "\n",
    "先验概率，就是常识、经验、统计学所透露出的“因”的概率，即瓜的颜色是青绿的概率。\n",
    "\n",
    "后验概率，就是在知道“果”之后，去推测“因”的概率，也就是说，如果已经知道瓜是好瓜，那么瓜的颜色是青绿的概率是多少。后验和先验的关系就需要运用贝叶斯决策理论来求解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 贝叶斯决策理论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "贝叶斯决策论是概率框架下实施决策的基本方法，对分类任务来说，在所有相关概率都已知的理想情形下，贝叶斯决策论考虑如何基于这些概率和误判损失来选择最优的类别标记。\n",
    "\n",
    "假设有N种可能标记， $λ_{ij}$是将类$c_j$误分类为$c_i$所产生的损失，基于后验概率$ P(c_i | x)$ 可以获得样本x分类为$c_i$所产生的期望损失 ，即在样本x上的条件风险：\n",
    "\n",
    "$$R(c_i|\\mathbf{x}) = \\sum_{j=1}^N \\lambda_{ij} P(c_j|\\mathbf{x})$$\n",
    "我们的任务是寻找一个判定准则 $h:X→Y$以最小化总体风险\n",
    "\n",
    "$$R(h)= \\mathbb{E}_x [R(h(\\mathbf(x)) | \\mathbf(x))]$$\n",
    "\n",
    "显然，对每个样本x，若h能最小化条件风险 $R(h((x))|(x))$,则总体风险R(h)也将被最小化。这就产生了贝叶斯判定准则：为最小化总体风险，只需要在每个样本上选择那个能使条件风险R(c|x)最小的类别标记，即：\n",
    "\n",
    "$$h^* (x) = argmin_{c\\in y} R(c|\\mathbf{x})$$\n",
    "此时，h 称作贝叶斯最优分类器，与之对应的总体风险R(h )称为贝叶斯风险，1-R(h*)反映了分类器能达到的最好性能，即机器学习所产生的模型精度的上限。\n",
    "\n",
    "具体来说，若目标是最小化分类错误率（对应0/1损失），则$λ_{ij}$可以用0/1损失改写，得到条件风险和最小化分类错误率的最优分类器分别为：\n",
    "$$R(c|\\mathbf{x}) = 1- P(c|\\mathbf{x})$$\n",
    "\n",
    "$$h^*(x) = argmax_{c\\in \\mathcal{Y}} P(c|\\mathbf{x})$$\n",
    "\n",
    "即对每个样本x，选择能使后验概率P(c|x)最大的类别标识。\n",
    "\n",
    "获得后验概率的两种方法：\n",
    "\n",
    "1. 判别式模型:给定x，可以通过直接建模P(c|x)来预测c。\n",
    "2. 生成模型:先对联合分布p(x, c)建模，然后再有此获得P(c|x)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 贝叶斯公式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对生成模型来说，必然考虑：\n",
    "$$P(c|x) = \\frac{P(x,c)}{P(x)} = \\frac{P(c) P(x|c)}{P(x)}$$\n",
    "其中P(c)是“先验概率”；\n",
    "\n",
    "P(x|c)是样本x对于类标记c的类条件概率，或称为“似然”；\n",
    "\n",
    "P(x)是用于归一化的“证据”因子。\n",
    "\n",
    "上式即为贝叶斯公式。\n",
    "\n",
    "可以将其看做$$P(类别|特征) = \\frac{P(特征,类别)}{P(特征)} = \\frac{P(类别) P(特征|类别)}{P(特征)}$$\n",
    "\n",
    "对类条件概率P(x|c)来说，直接根据样本出现的频率来估计将会遇到严重的困难，所以引入了极大似然估计。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 极大似然估计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "估计类条件概率有一种常用的策略就是先假定其具有某种确定的概率分布形式，再基于训练样本对概率分布的参数进行估计。假设P(x|c)具有某种确定的形式并且被参数$θ_c$ 唯一确定，则我们的任务就是利用训练结D估计参数 $θ_c$。为了明确期间，我们将P(x|c)记为$p(x|θc)$.\n",
    "\n",
    "举个通俗的例子：假设一个袋子装有白球与红球，比例未知，现在抽取10次（每次抽完都放回，保证事件独立性），假设抽到了7次白球和3次红球，在此数据样本条件下，可以采用最大似然估计法求解袋子中白球的比例（最大似然估计是一种“模型已定，参数未知”的方法）。当然，这种数据情况下很明显，白球的比例是70%，但如何通过理论的方法得到这个答案呢？一些复杂的条件下，是很难通过直观的方式获得答案的，这时候理论分析就尤为重要了，这也是学者们为何要提出最大似然估计的原因。我们可以定义从袋子中抽取白球和红球的概率如下：\n",
    "#### 极大似然估计\n",
    "估计类条件概率有一种常用的策略就是先假定其具有某种确定的概率分布形式，再基于训练样本对概率分布的参数进行估计。假设P(x|c)具有某种确定的形式并且被参数$θ_c$ 唯一确定，则我们的任务就是利用训练结D估计参数 $θ_c$。为了明确期间，我们将P(x|c)记为$p(x|θc)$.\n",
    "\n",
    "举个通俗的例子：假设一个袋子装有白球与红球，比例未知，现在抽取10次（每次抽完都放回，保证事件独立性），假设抽到了7次白球和3次红球，在此数据样本条件下，可以采用最大似然估计法求解袋子中白球的比例（最大似然估计是一种“模型已定，参数未知”的方法）。当然，这种数据情况下很明显，白球的比例是70%，但如何通过理论的方法得到这个答案呢？一些复杂的条件下，是很难通过直观的方式获得答案的，这时候理论分析就尤为重要了，这也是学者们为何要提出最大似然估计的原因。我们可以定义从袋子中抽取白球和红球的概率如下：\n",
    "#### 极大似然估计\n",
    "估计类条件概率有一种常用的策略就是先假定其具有某种确定的概率分布形式，再基于训练样本对概率分布的参数进行估计。假设P(x|c)具有某种确定的形式并且被参数$θ_c$ 唯一确定，则我们的任务就是利用训练结D估计参数 $θ_c$。为了明确期间，我们将P(x|c)记为$p(x|θc)$.\n",
    "\n",
    "举个通俗的例子：假设一个袋子装有白球与红球，比例未知，现在抽取10次（每次抽完都放回，保证事件独立性），假设抽到了7次白球和3次红球，在此数据样本条件下，可以采用最大似然估计法求解袋子中白球的比例（最大似然估计是一种“模型已定，参数未知”的方法）。当然，这种数据情况下很明显，白球的比例是70%，但如何通过理论的方法得到这个答案呢？一些复杂的条件下，是很难通过直观的方式获得答案的，这时候理论分析就尤为重要了，这也是学者们为何要提出最大似然估计的原因。我们可以定义从袋子中抽取白球和红球的概率如下：\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
